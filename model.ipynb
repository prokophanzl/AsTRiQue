{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d20554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# IMPORTS\n",
    "# ==============\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a383e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# CONFIG\n",
    "# ==============\n",
    "\n",
    "PREDICTOR1 = 'voicing'                    # first predictor column name\n",
    "PREDICTOR2 = 'duration'                   # second predictor column name\n",
    "FILENAME_COL = 'filename'                 # filename column name\n",
    "LABEL_MAPPING = {'s': 0, 'z': 1}          # binary output label mapping\n",
    "\n",
    "TARGET = 'answer_batch'                   # target column name\n",
    "DATA_PATH = 'data/data.csv'               # sound info data file path\n",
    "PARTICIPANT_CSV_DIR = 'data/participants' # participant CSV directory\n",
    "PROCESSED_PATH = 'data_processed.csv'     # processed data file path; leave blank to disable\n",
    "\n",
    "INIT_RANDOM_SAMPLES = 10                  # initial random samples to collect\n",
    "MIN_ITERATIONS = 30                       # minimum number of iterations\n",
    "CLEANSER_FREQUENCY = 0                    # insert a high-certainty sample every nth iteration to prevent participant fatigue (irrelevant for virtual agents); 0 to disable\n",
    "MODEL_CERTAINTY_CUTOFF = 0.95             # stopping certainty threshold\n",
    "PARTICIPANT_TO_MODEL = 'p03'              # participant ID to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# VIRTUAL AGENT FUNCTIONS\n",
    "# ==============\n",
    "\n",
    "def query_real_class(filename):\n",
    "    \"\"\"\n",
    "    Queries a virtual agent for a classification of a given sample\n",
    "    \"\"\"\n",
    "    # look into the participant's answer lookup table - PARTICIPANT_CSV_DIR/PARTICIPANT_TO_MODEL.csv\n",
    "    # return the real class based on LABEL_MAPPING\n",
    "    participant_answers = pd.read_csv(PARTICIPANT_CSV_DIR + '/' + PARTICIPANT_TO_MODEL + '.csv')\n",
    "    real_answer = participant_answers[participant_answers[FILENAME_COL] == filename][TARGET].values[0]\n",
    "    return LABEL_MAPPING[real_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25323a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# SHARED FUNCTIONS\n",
    "# ==============\n",
    "\n",
    "# create stimuli dataframe\n",
    "stimuli = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# add columns for classification order, classification type, real class, predicted class, and prediction certainty\n",
    "stimuli['classification_order'] = None\n",
    "stimuli['classification_type'] = None\n",
    "stimuli['real_class'] = None\n",
    "stimuli['predicted_class'] = None\n",
    "stimuli['prediction_certainty'] = None\n",
    "\n",
    "def get_sample(stimuli, iteration, active_learning_iteration):\n",
    "    \"\"\"\n",
    "    Returns a sample from the stimuli dataframe (uncertainty sampling with cleanser).\n",
    "    Takes a dataframe with only unlabeled samples and the current iteration in the active learning phase.\n",
    "    \"\"\"\n",
    "    # check if it is time for a cleanser (the single highest-certainty) sample, otherwise select the sample with the lowest certainty\n",
    "    if CLEANSER_FREQUENCY > 0 and active_learning_iteration % CLEANSER_FREQUENCY == 0:\n",
    "        print(f\"Iteration {iteration}: Cleanser (AL {active_learning_iteration})\")\n",
    "        return stimuli[stimuli['prediction_certainty'] == stimuli['prediction_certainty'].max()].sample(1)\n",
    "    else:\n",
    "        print(f\"Iteration {iteration}: Uncertainty sampling (AL {active_learning_iteration})\")\n",
    "        return stimuli[stimuli['prediction_certainty'] == stimuli['prediction_certainty'].min()].sample(1)\n",
    "\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"\n",
    "    Trains a logistic regression model based on the current state of the stimuli dataframe.\n",
    "    Updates predicted_class and prediction_certainty for unlabeled samples.\n",
    "    \"\"\"\n",
    "\n",
    "    # filter to only labeled samples\n",
    "    valid = stimuli['real_class'].isin([0, 1])\n",
    "    if valid.sum() < 2:\n",
    "        raise ValueError(\"Not enough labeled samples to train the model.\")\n",
    "\n",
    "    # features and labels\n",
    "    X_train = stimuli.loc[valid, [PREDICTOR1, PREDICTOR2]]\n",
    "    y_train = stimuli.loc[valid, 'real_class'].astype(int)\n",
    "\n",
    "    # define and train logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # apply model to unlabeled data\n",
    "    unknown = stimuli['real_class'].isna()\n",
    "    if unknown.sum() == 0:\n",
    "        print(\"No unknown samples to predict.\")\n",
    "        return model\n",
    "\n",
    "    X_test = stimuli.loc[unknown, [PREDICTOR1, PREDICTOR2]]\n",
    "    probs = model.predict_proba(X_test)\n",
    "\n",
    "    # predicted class (0 or 1) and associated certainty\n",
    "    predicted = model.predict(X_test)\n",
    "    certainty = probs.max(axis=1)\n",
    "\n",
    "    # store predictions in dataframe\n",
    "    stimuli.loc[unknown, 'predicted_class'] = predicted\n",
    "    stimuli.loc[unknown, 'prediction_certainty'] = certainty\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_results(answered_data, unanswered_data, model):\n",
    "    \"\"\"Visualize results with decision boundary and improved legend/color bar\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "    \n",
    "    # convert answers to numeric if necessary\n",
    "    if answered_data['real_class'].dtype == 'object':\n",
    "        answered_data = answered_data.copy()\n",
    "        answered_data['real_class'] = answered_data['real_class'].astype(int)\n",
    "        \n",
    "    # plot answered points, split by class\n",
    "    for label_char, label_num in LABEL_MAPPING.items():\n",
    "        subset = answered_data[answered_data['real_class'] == label_num]\n",
    "        if not subset.empty:\n",
    "            plt.scatter(\n",
    "                subset[PREDICTOR1],\n",
    "                subset[PREDICTOR2],\n",
    "                c='blue' if label_num == 0 else 'red',\n",
    "                label=f\"answered ({label_char})\",\n",
    "                edgecolors='k'\n",
    "            )\n",
    "\n",
    "    # plot unanswered points\n",
    "    if not unanswered_data.empty:\n",
    "        plt.scatter(\n",
    "            unanswered_data[PREDICTOR1], \n",
    "            unanswered_data[PREDICTOR2],\n",
    "            c='gray',\n",
    "            alpha=0.5,\n",
    "            label='unanswered'\n",
    "        )\n",
    "    \n",
    "    # decision boundary grid\n",
    "    x_min, x_max = stimuli[PREDICTOR1].min() - 1, stimuli[PREDICTOR1].max() + 1\n",
    "    y_min, y_max = stimuli[PREDICTOR2].min() - 1, stimuli[PREDICTOR2].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    grid_points = pd.DataFrame(\n",
    "        np.c_[xx.ravel(), yy.ravel()],\n",
    "        columns=[PREDICTOR1, PREDICTOR2]\n",
    "    )\n",
    "    \n",
    "    Z = model.predict_proba(grid_points)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # show background decision gradient\n",
    "    contour = plt.contourf(xx, yy, Z, alpha=0.3, levels=20, cmap='coolwarm')\n",
    "    \n",
    "    # custom color bar with labels s and z\n",
    "    cbar = plt.colorbar(contour, ticks=[0, 1])\n",
    "    rev_label_map = {v: k for k, v in LABEL_MAPPING.items()}\n",
    "    cbar.ax.set_yticklabels([rev_label_map[0], rev_label_map[1]])\n",
    "    cbar.set_label('predicted answer')\n",
    "    \n",
    "    plt.xlabel(PREDICTOR1)\n",
    "    plt.ylabel(PREDICTOR2)\n",
    "    plt.title(f'Virtual Agent Results (participant: {PARTICIPANT_TO_MODEL})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(stimuli, filename_col):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions on the unanswered data by comparing them to real labels\n",
    "    obtained via query_real_class().\n",
    "    \"\"\"\n",
    "    # get unanswered data\n",
    "    unanswered = stimuli[stimuli['real_class'].isna()].copy()\n",
    "    \n",
    "    if unanswered.empty:\n",
    "        print(\"No unanswered data to evaluate.\")\n",
    "        return\n",
    "\n",
    "    # query the actual class for evaluation\n",
    "    true_labels = []\n",
    "    predicted_labels = unanswered['predicted_class'].tolist()\n",
    "\n",
    "    print(\"Evaluating model predictions on unanswered data...\")\n",
    "\n",
    "    for fname in unanswered[filename_col]:\n",
    "        true_label = int(query_real_class(fname))\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "    # calculate metrics\n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "    print(\"\\n=== Evaluation on Unanswered Data ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# MAIN EXECUTION\n",
    "# ==============\n",
    "\n",
    "# initial random sampling with class balance\n",
    "collected_classes = set()\n",
    "\n",
    "iteration = 1\n",
    "while iteration <= INIT_RANDOM_SAMPLES or len(collected_classes) < 2:\n",
    "    print(f\"Iteration {iteration}: Random sampling\")\n",
    "\n",
    "    # select a random stimulus where real class is unknown\n",
    "    sample = stimuli[stimuli['real_class'].isna()].sample(1)\n",
    "\n",
    "    # get classification, querying filename\n",
    "    classification = int(query_real_class(sample[FILENAME_COL].values[0]))\n",
    "    \n",
    "    collected_classes.add(classification)\n",
    "\n",
    "    # update row in dataframe\n",
    "    idx = stimuli[FILENAME_COL] == sample[FILENAME_COL].values[0]\n",
    "    stimuli.loc[idx, 'classification_order'] = iteration\n",
    "    stimuli.loc[idx, 'classification_type'] = 'random'\n",
    "    stimuli.loc[idx, 'real_class'] = classification\n",
    "\n",
    "    iteration += 1\n",
    "\n",
    "# train initial model\n",
    "model = train_model()\n",
    "\n",
    "# active learning phase\n",
    "active_learning_iteration = 1\n",
    "\n",
    "while True:\n",
    "    # retrain model to get up-to-date predictions on remaining unlabeled samples\n",
    "    model = train_model()\n",
    "\n",
    "    # get updated unanswered subset\n",
    "    unanswered = stimuli[stimuli['real_class'].isna()]\n",
    "    \n",
    "    # check stopping condition\n",
    "    below_cutoff = unanswered['prediction_certainty'] < MODEL_CERTAINTY_CUTOFF\n",
    "    if below_cutoff.sum() == 0 and active_learning_iteration >= MIN_ITERATIONS:\n",
    "        print(\"Stopping active learning: all predictions above certainty threshold \"\n",
    "              f\"({MODEL_CERTAINTY_CUTOFF}) and minimum iterations met ({MIN_ITERATIONS}).\")\n",
    "        break\n",
    "\n",
    "    # select next sample using uncertainty sampling (with optional cleanser)\n",
    "    sample = get_sample(unanswered, iteration, active_learning_iteration)\n",
    "\n",
    "    # query real classification\n",
    "    classification = int(query_real_class(sample[FILENAME_COL].values[0]))\n",
    "\n",
    "    # update row in dataframe\n",
    "    idx = stimuli[FILENAME_COL] == sample[FILENAME_COL].values[0]\n",
    "    stimuli.loc[idx, 'classification_order'] = iteration\n",
    "    stimuli.loc[idx, 'classification_type'] = 'active'\n",
    "    stimuli.loc[idx, 'real_class'] = classification\n",
    "\n",
    "    iteration += 1\n",
    "    active_learning_iteration += 1\n",
    "\n",
    "# split answered and unanswered data\n",
    "answered = stimuli[stimuli['real_class'].notna()]\n",
    "unanswered = stimuli[stimuli['real_class'].isna()]\n",
    "\n",
    "# evaluate model\n",
    "evaluate_model(stimuli, FILENAME_COL)\n",
    "\n",
    "# plot the results\n",
    "plot_results(answered, unanswered, model)\n",
    "\n",
    "# save dataframe\n",
    "if PROCESSED_PATH:\n",
    "    stimuli.to_csv(PROCESSED_PATH, index = False)\n",
    "    print(f\"Processed data saved to {PROCESSED_PATH}\")\n",
    "else:\n",
    "    print(\"Processed data not saved - PROCESSED_PATH is empty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e846a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astrique",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
